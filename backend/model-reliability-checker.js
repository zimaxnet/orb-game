import { OpenAIClient, AzureKeyCredential } from '@azure/openai';
import { StoryCacheService } from './story-cache-service.js';

export class ModelReliabilityChecker {
  constructor(secrets) {
    this.secrets = secrets;
    this.reliableModels = [];
    this.models = [
      { id: 'o4-mini', name: 'O4-Mini', testFunction: this.testAzureOpenAI.bind(this) }
    ];
  }

  /**
   * Check reliability of all available models
   */
  async checkModelReliability() {
    console.log('üîç Checking model reliability...');
    
    const models = [
      { id: 'azure-openai', name: 'Azure OpenAI (gpt-5-mini)', testFunction: this.testAzureOpenAI.bind(this) }
    ];

    const reliabilityResults = [];

    for (const model of models) {
      try {
        console.log(`üß™ Testing ${model.name}...`);
        const isReliable = await model.testFunction();
        
        if (isReliable) {
          this.reliableModels.push(model.id);
          console.log(`‚úÖ ${model.name} is reliable`);
        } else {
          console.log(`‚ùå ${model.name} is not reliable`);
        }
        
        reliabilityResults.push({
          model: model.id,
          name: model.name,
          reliable: isReliable
        });
      } catch (error) {
        console.error(`‚ùå Error testing ${model.name}:`, error.message);
        reliabilityResults.push({
          model: model.id,
          name: model.name,
          reliable: false,
          error: error.message
        });
      }
    }

    console.log(`üìä Model reliability results:`, reliabilityResults);
    console.log(`‚úÖ Reliable models:`, this.reliableModels);

    return {
      reliableModels: this.reliableModels,
      results: reliabilityResults
    };
  }

  /**
   * Test Azure OpenAI model using the correct API version
   */
  async testAzureOpenAI() {
    try {
      if (!this.secrets.AZURE_OPENAI_API_KEY) {
        console.warn('‚ö†Ô∏è Azure OpenAI API key not available');
        return false;
      }

      const AZURE_OPENAI_ENDPOINT = 'https://aimcs-foundry.cognitiveservices.azure.com/';
      const AZURE_OPENAI_DEPLOYMENT = 'gpt-5-mini';
      const azureOpenAIApiKey = this.secrets.AZURE_OPENAI_API_KEY;

      console.log('üß™ Testing Azure OpenAI connection...');
      console.log(`   Endpoint: ${AZURE_OPENAI_ENDPOINT}`);
      console.log(`   Deployment: ${AZURE_OPENAI_DEPLOYMENT}`);
      console.log(`   API Key: ${azureOpenAIApiKey ? '‚úÖ Available' : '‚ùå Missing'}`);

      // Use a simpler test prompt that won't hit token limits
      const testPrompt = 'Write a short positive story about technology. Keep it under 50 words.';

      const requestBody = {
        model: AZURE_OPENAI_DEPLOYMENT,
        messages: [
          {
            role: 'user',
            content: testPrompt
          }
        ],
        max_completion_tokens: 200 // Increased token limit for better test reliability
      };

      console.log('üì§ Sending test request to Azure OpenAI...');

      const response = await fetch(`${AZURE_OPENAI_ENDPOINT}openai/deployments/${AZURE_OPENAI_DEPLOYMENT}/chat/completions?api-version=2024-12-01-preview`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${azureOpenAIApiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify(requestBody)
      });

      console.log(`üì• Response status: ${response.status} ${response.statusText}`);

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`‚ùå Azure OpenAI API error: ${response.status} - ${errorText}`);
        return false;
      }

      const data = await response.json();
      console.log('üìä Response data received');
      
      if (data.choices && data.choices.length > 0) {
        console.log('‚úÖ Choices array found');
        
        const choice = data.choices[0];
        const content = choice.message?.content;
        const finishReason = choice.finish_reason;
        
        console.log('üìÑ Content available:', !!content);
        console.log('üèÅ Finish reason:', finishReason);
        
        if (content && content.trim()) {
          console.log('üìù Content received successfully');
          console.log('üìÑ Content preview:', content.substring(0, 100) + '...');
          
          // For this test, we just need to verify the model can generate content
          // We don't need to parse JSON for the reliability test
          console.log('‚úÖ Azure OpenAI test passed - model is reliable');
          return true;
        } else if (finishReason === 'length') {
          // Model hit token limit but responded successfully - this is still reliable
          console.log('üìù Model hit token limit but responded successfully');
          console.log('‚úÖ Azure OpenAI test passed - model is reliable (token limit reached)');
          return true;
        } else {
          console.error('‚ùå No content in response choices');
          console.log('üìã Full response data:', JSON.stringify(data, null, 2));
          return false;
        }
      } else {
        console.error('‚ùå No choices in response');
        console.log('üìã Full response data:', JSON.stringify(data, null, 2));
        return false;
      }
    } catch (error) {
      console.error('‚ùå Azure OpenAI test failed:', error.message);
      console.error('   Full error:', error);
      return false;
    }
  }

  /**
   * Cache a modern epoch story for quick access (disabled for now)
   */
  async cacheModernEpochStory() {
    // Story caching disabled - not critical for main functionality
    // This was causing errors with o1 model response format
    console.log('‚ÑπÔ∏è Modern epoch story caching disabled');
    return false;
  }

  /**
   * Generate Azure OpenAI story using the correct API
   */
  async generateAzureOpenAIStory(category, epoch, count) {
    try {
      if (!this.secrets.AZURE_OPENAI_API_KEY) {
        throw new Error('Azure OpenAI API key not available');
      }

      const AZURE_OPENAI_ENDPOINT = 'https://aimcs-foundry.cognitiveservices.azure.com/';
      const AZURE_OPENAI_DEPLOYMENT = 'gpt-5-mini';
      const azureOpenAIApiKey = this.secrets.AZURE_OPENAI_API_KEY;

      const prompt = `Generate ${count} brief positive news stories about ${category.toLowerCase()} in ${epoch.toLowerCase()} times. Return ONLY a valid JSON array with this exact format: [{ "headline": "Brief headline", "summary": "One sentence summary", "fullText": "2-3 sentence story", "source": "GPT-5-Mini" }]`;

      const response = await fetch(`${AZURE_OPENAI_ENDPOINT}openai/deployments/${AZURE_OPENAI_DEPLOYMENT}/chat/completions?api-version=2024-12-01-preview`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${azureOpenAIApiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: AZURE_OPENAI_DEPLOYMENT,
          messages: [
            {
              role: 'user',
              content: prompt
            }
          ],
          max_completion_tokens: 1000
        })
      });

      if (!response.ok) {
        throw new Error(`Azure OpenAI API error: ${response.status}`);
      }

      const data = await response.json();
      const content = data.choices[0]?.message?.content;
      
      if (!content) return [];

      // Try to parse JSON response
      try {
        const stories = JSON.parse(content);
        return Array.isArray(stories) ? stories : [];
      } catch {
        return [];
      }
    } catch (error) {
      console.error('‚ùå Failed to generate Azure OpenAI story:', error.message);
      return [];
    }
  }

  /**
   * Get cached modern story
   */
  getCachedModernStory() {
    return this.cachedModernStory || null;
  }

  /**
   * Get list of reliable models
   */
  getReliableModels() {
    return this.reliableModels;
  }
} 